import os
import re
from pathlib import Path
from datetime import datetime
from jinja2 import Template
from .base import PipelineStage
from typing import Dict, Any, Optional

from dotenv import load_dotenv
load_dotenv()

try:
    from gpt4all import GPT4All
    gpt4all_model_path = str(Path(os.getenv("GPT4ALL_MODEL_PATH")).absolute())
    gpt4all_model_name = os.getenv("GPT4ALL_MODEL_NAME")
    gpt4all_model = GPT4All(model_name=gpt4all_model_name, model_path=gpt4all_model_path, allow_download=False) if gpt4all_model_name else None
except ImportError:
    gpt4all_model = None

try:
    import openai
    openai.api_key = os.getenv("OPENAI_API_KEY")
except ImportError:
    openai = None


class GPTStage(PipelineStage):
    """
    GPTStage —Ä–µ–Ω–¥–µ—Ä–∏—Ç prompt –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –µ–≥–æ –≤ GPT4All (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é) –∏–ª–∏ OpenAI (—Ñ–æ–ª–±—ç–∫).
    –û—Ç–≤–µ—Ç –æ—á–∏—â–∞–µ—Ç—Å—è –æ—Ç —Å–ª—É–∂–µ–±–Ω—ã—Ö —Ç–µ–≥–æ–≤ –∏ –ø–∞—Ä—Å–∏—Ç—Å—è –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π dict.
    """

    def run(self, data: Dict[str, Any]) -> Dict[str, Any]:
        print("\n" + "="*50)
        print("üöÄ –ó–∞–ø—É—Å–∫ GPTStage –¥–ª—è –º–∞—Å—Å–∏–≤–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        print("="*50)
        
        if not hasattr(self.config, "gpt"):
            return data

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –æ—Ç–≤–µ—Ç—ã GPT
        gpt_responses = {}
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –±–ª–æ–∫–∏-–º–∞—Å—Å–∏–≤—ã
        for block_name, items in data.items():
            if not isinstance(items, list):
                continue
                
            print(f"\nüîß –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–ª–æ–∫–∞ '{block_name}' ({len(items)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)")
            
            for i, item in enumerate(items):
                if not isinstance(item, dict):
                    continue
                    
                print(f"\nüìÑ –î–æ–∫—É–º–µ–Ω—Ç #{i+1}: {item.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}")
                doc_id = f"{block_name}_{i}"
                
                # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
                text = self._get_single_text(item)
                if not text:
                    gpt_responses[doc_id] = {"error": "Empty input text"}
                    continue
                    
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –∏ –ø–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç
                prompt = self._render_prompt(text, item)
                response = self._get_gpt_response(prompt)
                
                # –ü–∞—Ä—Å–∏–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                parsed = self._parse_response(self._clean_model_output(response))
                gpt_responses[doc_id] = {
                    **parsed,
                    "_meta": {
                        "model": self._get_model_info(),
                        "prompt_length": len(prompt),
                        "response_length": len(response)
                    }
                }
                
                # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Å–∞–º –¥–æ–∫—É–º–µ–Ω—Ç
                item["gpt"] = gpt_responses[doc_id]
        
        return {
            **data,
            "gpt_responses": gpt_responses
        }

    def _process_single_item(self, item: Dict[str, Any]) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω –¥–æ–∫—É–º–µ–Ω—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç"""
        text = self._get_single_text(item)
        if not text:
            return {"error": "Empty input text"}

        prompt = self._render_prompt(text, item)
        response = self._get_gpt_response(prompt)
        
        return self._parse_response(self._clean_model_output(response))

    def _get_single_text(self, item: Dict[str, Any]) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –æ–¥–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        for field in ["gpt_text", "excerpt", "text"]:
            text = item.get(field)
            if text and isinstance(text, str) and text.strip():
                return text.strip()
        return ""    
    
    def _render_prompt(self, text: str, data: Dict[str, Any]) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ–º–ø—Ç —Å —è–≤–Ω—ã–º —É–∫–∞–∑–∞–Ω–∏–µ–º —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Ç–≤–µ—Ç–∞"""
        prompt_template = (
            self.config.gpt.prompt + 
            "\n\n–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –¥–∞–µ—Ç —á–µ—Ç–∫–∏–µ –∏ –∫–æ—Ä–æ—Ç–∫–∏–µ –æ—Ç–≤–µ—Ç—ã." 
            "\n–ù–µ —Ä–∞—Å—Å—É–∂–¥–∞–π, –ø—Ä–æ—Å—Ç–æ –æ—Ç–≤–µ—á–∞–π –ø–æ –¥–µ–ª—É." 
            "\n\n–û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π –∏ —Ç–µ–≥–æ–≤."
            "\n–ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ç–µ–≥–∏ <think> –∏–ª–∏ –¥—Ä—É–≥–∏–µ XML-—Ä–∞–∑–º–µ—Ç–∫–∏."
        )
        
        context = {
            "text": text,
            "now": datetime.now(),
            **data.get("auto_dates", {}),
            **data.get("gpt", {}),
            **data.get("normalized", {}),
        }
        
        prompt = Template(prompt_template).render(**context)
        
        print("\nüß† –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π prompt:\n" + "-" * 40)
        print(prompt[:500] + "..." if len(prompt) > 500 else prompt)
        print("-" * 40)
        print(f"–î–ª–∏–Ω–∞ prompt: {len(prompt)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        self._save_debug("prompt", prompt)
        return prompt

    def _get_gpt_response(self, prompt: str) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç GPT —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        # GPT4All
        if gpt4all_model:
            try:
                print(f"\nüöÄ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è GPT4All: {os.path.basename(gpt4all_model_path)}")
                response = ""
                
                print("üì° –ü–æ—Ç–æ–∫–æ–≤—ã–π –æ—Ç–≤–µ—Ç (—Å—ã—Ä–æ–π):")
                for chunk in gpt4all_model.generate(
                    prompt,
                    max_tokens=1024,
                    streaming=True,
                    temp=0.3, 
                    top_k=30,  
                    top_p=0.8,   
                ):
                    print(chunk, end="", flush=True)
                    response += chunk
                
                print("\n" + "-" * 40)
                return response
                
            except Exception as e:
                return {"error": f"GPT4All error: {e}"}

        # OpenAI fallback
        elif openai and os.getenv("OPENAI_API_KEY"):
            try:
                print("\nüåê –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è OpenAI: gpt-3.5-turbo")
                response = openai.ChatCompletion.create(
                    model="gpt-3.5-turbo",
                    messages=[{
                        "role": "system",
                        "content": "–û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –ø–æ —Ñ–æ—Ä–º–∞—Ç—É –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π"
                    }, {
                        "role": "user",
                        "content": prompt
                    }],
                    temperature=0.3
                )
                return response.choices[0].message.content.strip()
                
            except Exception as e:
                return {"error": f"OpenAI error: {e}"}

        return {"error": "No GPT backend available"}

    def _clean_model_output(self, text: str) -> str:
        """–û—á–∏—â–∞–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç —Å–ª—É–∂–µ–±–Ω—ã—Ö —Ç–µ–≥–æ–≤ –∏ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π –º–æ–¥–µ–ª–∏"""
        # –£–¥–∞–ª—è–µ–º –≤—Å–µ –¥–æ –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–≥–æ —Ç–µ–≥–∞ </think> –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
        if '</think>' in text:
            text = text.split('</think>')[-1].strip()
        
        # –£–¥–∞–ª—è–µ–º –≤—Å–µ XML-–ø–æ–¥–æ–±–Ω—ã–µ —Ç–µ–≥–∏
        text = re.sub(r'<\/?[a-z]+>', '', text)
        
        # –£–¥–∞–ª—è–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        text = re.sub(r'\n{3,}', '\n\n', text)
        
        print("\nüîß –û—á–∏—â–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç:\n" + "-" * 40)
        print(text[:1000] + "..." if len(text) > 1000 else text)
        print("-" * 40)
        
        return text.strip()

    def _parse_response(self, text: str) -> Dict[str, str]:
        """–°—Ç—Ä–æ–≥–∏–π –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –ø–æ —Ñ–æ—Ä–º–∞—Ç—É –∫–ª—é—á: –∑–Ω–∞—á–µ–Ω–∏–µ"""
        result = {}
        current_key = None
        
        for line in text.splitlines():
            line = line.strip()
            if not line:
                continue
                
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º ":"
            if ":" in line:
                if current_key:  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                    result[current_key] = result[current_key].strip()
                
                key, val = line.split(":", 1)
                current_key = key.strip().lower().replace(" ", "_")
                result[current_key] = val.strip()
            elif current_key:  # –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
                result[current_key] += " " + line
                
        # –£–¥–∞–ª—è–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –∏–∑ –∑–Ω–∞—á–µ–Ω–∏–π
        for key in result:
            result[key] = re.sub(r'\[\d+\]', '', result[key])
            
        return result

    def _get_text(self, data: Dict[str, Any]) -> Dict[str, str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å {doc_id: text} –¥–ª—è –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        texts = {}
        
        for block_name, items in data.items():
            if not isinstance(items, list):
                continue
                
            for i, item in enumerate(items):
                sources = [
                    item.get("gpt_text"),
                    item.get("excerpt"),
                    item.get("text")
                ]
                for text in sources:
                    if text and isinstance(text, str) and text.strip():
                        texts[f"{block_name}_{i}"] = text.strip()
                        break
                        
        return texts

    def _log_text_source(self, data: Dict[str, Any], selected_text: str) -> None:
        """–õ–æ–≥–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è GPT"""
        print("\nüîç –ò—Å—Ç–æ—á–Ω–∏–∫ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è GPT:")
        print(f"  - –î–ª–∏–Ω–∞: {len(selected_text)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"  - –ü—Ä–∏–º–µ—Ä: {selected_text[:200]}...")

    def _detect_text_source(self, data: Dict[str, Any], text: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö"""
        sources = {
            "gpt_text": data.get("gpt_text"),
            "excerpt": data.get("excerpt"),
            "text": data.get("text")
        }
        
        for name, source_text in sources.items():
            if source_text and source_text.strip() == text.strip():
                return name
                
        return "nested_text"

    def _get_model_info(self) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–π –º–æ–¥–µ–ª–∏"""
        if gpt4all_model:
            return f"GPT4All-{os.path.basename(gpt4all_model_path)}"
        elif openai:
            return "OpenAI-gpt-3.5-turbo"
        return "unknown"

    def _save_debug(self, name: str, content: str) -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —Ñ–∞–π–ª"""
        try:
            log_dir = Path("logs/gpt_debug")
            log_dir.mkdir(parents=True, exist_ok=True)
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            with open(log_dir / f"{name}_{ts}.txt", "w", encoding="utf-8") as f:
                f.write(content)
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å {name}-–ª–æ–≥: {e}")