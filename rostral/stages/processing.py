import os
import re
import fitz  # PyMuPDF
import pytesseract
from PIL import Image
from io import BytesIO
from datetime import datetime
from typing import Dict, Any, List
import typer
from .base import PipelineStage
from rostral.db import get_event_hash, is_known_by_hash

MAX_FRAGMENT_LENGTH = int(os.getenv("GPT_FRAGMENT_MAX_LENGTH", 200))
TEXT_MAX_LENGTH = int(os.getenv("GPT_TEXT_MAX_LENGTH", 2000))
CHUNK_HEAD = int(os.getenv("GPT_CHUNK_HEAD", TEXT_MAX_LENGTH // 2))
CHUNK_TAIL = int(os.getenv("GPT_CHUNK_TAIL", TEXT_MAX_LENGTH // 2))

import re
from typing import List, Dict, Any

def extract_text_fragments(text: str, regex_patterns: List[str]) -> str:
    """
    Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð½Ð°Ñ Ð²ÐµÑ€ÑÐ¸Ñ Ñ Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ñ‹Ð¼ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ regex
    """
    print("âœ… extract_text_fragments function called")
    print(f"ðŸ“ Text length: {len(text)} symbols")
    print(f"ðŸ”Ž Patterns: {regex_patterns}")
    if not text:
        return "âš  There is no text to process"
    
    if not regex_patterns:
        return "âš  There are no regex patterns to apply"

    fragments = []
    debug_info = []  # Ð”Ð»Ñ Ð¾Ñ‚Ð»Ð°Ð´Ð¾Ñ‡Ð½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸
    
    for pattern in regex_patterns:
        try:
            debug_info.append(f"\nðŸ” Pattern analys: '{pattern}'")
            matches = list(re.finditer(pattern, text, re.DOTALL | re.IGNORECASE))
            
            if not matches:
                debug_info.append("   âž¤ No mathes found")
                continue
                
            debug_info.append(f"   âž¤ Matches found: {len(matches)}")
            
            for i, match in enumerate(matches, 1):
                start = match.end()
                end = min(len(text), start + 200)
                fragment = text[start:end].strip()
                
                debug_info.append(f"\n   ðŸ”¹ Match #{i}:")
                debug_info.append(f"      Position: {match.start()}-{match.end()}")
                debug_info.append(f"      Matched text: '{match.group()}'")
                debug_info.append(f"      Context (200 symbols after):\n      '{fragment}'")
                
                if fragment:
                    label = {
                        r'Ð£Ð¢Ð’Ð•Ð Ð–Ð”ÐÐ®': 'ðŸ”¹ Ð£Ñ‚Ð²ÐµÑ€Ð¶Ð´Ð°ÑŽÑ‰Ð°Ñ Ð¾Ñ€Ð³Ð°Ð½Ð¸Ð·Ð°Ñ†Ð¸Ñ',
                        r'Ð°Ð´Ñ€ÐµÑ[Ñƒ]?:': 'ðŸ“ ÐÐ´Ñ€ÐµÑ Ð¾Ð±ÑŠÐµÐºÑ‚Ð°', 
                        r'Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð¾Ð¼': 'ðŸ“‹ Ð”ÐµÑ‚Ð°Ð»Ð¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°',
                        r'ÑÐ¾Ð±ÑÑ‚Ð²ÐµÐ½Ð½Ð¸ÐºÐ¾Ð¼': 'ðŸ‘¤ Ð¡Ð¾Ð±ÑÑ‚Ð²ÐµÐ½Ð½Ð¸Ðº',
                        r'ÐšÑ€Ð°Ñ‚ÐºÐ¸Ðµ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ': 'ðŸ“œ Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ‡ÐµÑÐºÐ°Ñ ÑÐ¿Ñ€Ð°Ð²ÐºÐ°'
                    }.get(pattern, f'âš™ï¸ ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ Ð¿Ð¾ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ñƒ "{pattern}"')
                    
                    fragments.append(f"{label}:\n{fragment}\n{'â”'*40}")

        except re.error as e:
            debug_info.append(f"   âŒ Pattern error: {str(e)}")
            continue

    # Ð’Ñ‹Ð²Ð¾Ð´ Ð¾Ñ‚Ð»Ð°Ð´Ð¾Ñ‡Ð½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð² ÐºÐ¾Ð½ÑÐ¾Ð»ÑŒ
    print("\n".join(debug_info))
    
    return "\n\n".join(fragments) if fragments else "No relevant text found"
class ProcessingStage(PipelineStage):
    def run(self, data: Dict[str, Any]) -> Dict[str, Any]:
        processing_meta = {
            "timestamp": datetime.now().isoformat(),
            "processed_files": 0,
            "errors": []
        }

        typer.echo(f"âš™ï¸ ProcessingStage input data: {type(data)}")
        typer.echo(f"ðŸ“ ENV limits: fragment={MAX_FRAGMENT_LENGTH}, gpt_text={TEXT_MAX_LENGTH}, head={CHUNK_HEAD}, tail={CHUNK_TAIL}")

        if not isinstance(data, dict):
            typer.echo("â„¹ï¸ Input data is not a dictionary, skipping processing")
            return data

        for block_name, items in data.items():
            if not isinstance(items, list):
                typer.echo(f"ðŸ”¸ Skipping block '{block_name}' (not a list)")
                continue

            typer.echo(f"ðŸ”§ Processing block '{block_name}' with {len(items)} items")
            data[block_name] = [r for r in items if self._process_record(r, processing_meta)]

        data["__processing__"] = processing_meta
        typer.echo(f"âœ… Processed {processing_meta['processed_files']} PDF files")

        if "events" in data:
            for i, event in enumerate(data["events"]):
                typer.echo(f"ðŸ“„ Document #{i+1}: {event.get('title', 'No title')}")
                
        else:
            typer.echo("âŒ 'events' block not found in data")

        return data

    def _process_record(self, record: Dict[str, Any], meta: Dict[str, Any]) -> bool:
        if not record.get("file_content") or ".pdf" not in record.get("url", "").lower():
            typer.echo("âŒ Ð¤Ð°Ð¹Ð» is not PDF, skipping")
            return False

        try:
            text = self._extract_pdf_text(record["file_content"])
            record["text"] = text
            record["event_id"] = get_event_hash(record)

            if is_known_by_hash(record):
                typer.echo(f"â­ï¸ Skipping: already seen â†’ {record['url']}")
                return False

            del record["file_content"]
            meta["processed_files"] += 1
            typer.echo(f"ðŸ“ Extracted text from PDF ({len(text)} chars)")
        except Exception as e:
            error_msg = f"Failed to process PDF: {str(e)}"
            record["text"] = f"[ERROR: {error_msg}]"
            record["error"] = error_msg
            meta["errors"].append({
                "url": record.get("url", "unknown"),
                "error": error_msg
            })
            typer.echo(f"âŒ {error_msg}")
            return False

        regex_patterns = getattr(self.config.processing, "extract_regex", [])
        print ('ÐŸÐÐ¢Ð¢Ð•Ð ÐÐ«', len(regex_patterns), regex_patterns)
        if regex_patterns:
            excerpt = extract_text_fragments(text, regex_patterns)
            print(f"âš™ï¸ Used regex-patterns: {regex_patterns}")
            record["excerpt"] = excerpt
            if not excerpt.strip():
                typer.echo(f"âš ï¸ Keywords were not found in the text â†’ {record.get('url')}")
            
            typer.echo(f"ðŸ” excerpt by regex_patterns â†’ {len(excerpt)} chars")
            
        else:
            if len(text) > TEXT_MAX_LENGTH:
                record["excerpt"] = f"{text[:CHUNK_HEAD]} ... {text[-CHUNK_TAIL:]}"
                typer.echo(f"âœ‚ï¸ gpt_text trimmed from full text to {len(record['excerpt'])} chars")
            else:
                record["excerpt"] = text

        return True

    def _extract_pdf_text(self, pdf_content: bytes, max_pages: int = 10) -> str:
        text_parts = []
        doc = fitz.open(stream=BytesIO(pdf_content), filetype="pdf")
        for page_num in range(min(len(doc), max_pages)):
            page = doc.load_page(page_num)
            text = self._extract_page_text(page)
            if text:
                text_parts.append(text)
        return "\n".join(text_parts).strip()

    def _extract_page_text(self, page) -> str:
        text = page.get_text().strip()
        if text:
            return text
        try:
            pix = page.get_pixmap(dpi=300)
            img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
            return pytesseract.image_to_string(img, lang="rus+eng").strip()
        except Exception as e:
            return f"[OCR failed: {str(e)}]"
