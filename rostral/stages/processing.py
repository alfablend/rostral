import os
import re
import fitz  # PyMuPDF
import pytesseract
from PIL import Image
from io import BytesIO
from datetime import datetime
from typing import Dict, Any, List
import typer
from .base import PipelineStage
from rostral.db import get_event_hash, is_known_by_hash

MAX_FRAGMENT_LENGTH = int(os.getenv("GPT_FRAGMENT_MAX_LENGTH", 200))
TEXT_MAX_LENGTH = int(os.getenv("GPT_TEXT_MAX_LENGTH", 2000))
CHUNK_HEAD = int(os.getenv("GPT_CHUNK_HEAD", TEXT_MAX_LENGTH // 2))
CHUNK_TAIL = int(os.getenv("GPT_CHUNK_TAIL", TEXT_MAX_LENGTH // 2))

import re
from typing import List, Dict, Any

def extract_text_fragments(text: str, regex_patterns: List[str]) -> str:
    """
    Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð½Ð°Ñ Ð²ÐµÑ€ÑÐ¸Ñ Ñ Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ñ‹Ð¼ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ regex
    """
    print("âœ… Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ extract_text_fragments Ð²Ñ‹Ð·Ð²Ð°Ð½Ð°")
    print(f"ðŸ“ Ð”Ð»Ð¸Ð½Ð° Ñ‚ÐµÐºÑÑ‚Ð°: {len(text)} ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²")
    print(f"ðŸ”Ž ÐŸÐ°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹: {regex_patterns}")
    if not text:
        return "âš  Ð¢ÐµÐºÑÑ‚ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚"
    
    if not regex_patterns:
        return "âš  ÐÐµ Ð·Ð°Ð´Ð°Ð½Ñ‹ regex-Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹ Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ°"

    fragments = []
    debug_info = []  # Ð”Ð»Ñ Ð¾Ñ‚Ð»Ð°Ð´Ð¾Ñ‡Ð½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸
    
    for pattern in regex_patterns:
        try:
            debug_info.append(f"\nðŸ” ÐÐ½Ð°Ð»Ð¸Ð· Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð°: '{pattern}'")
            matches = list(re.finditer(pattern, text, re.DOTALL | re.IGNORECASE))
            
            if not matches:
                debug_info.append("   âž¤ Ð¡Ð¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ð¹ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾")
                continue
                
            debug_info.append(f"   âž¤ ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ð¹: {len(matches)}")
            
            for i, match in enumerate(matches, 1):
                start = match.end()
                end = min(len(text), start + 200)
                fragment = text[start:end].strip()
                
                debug_info.append(f"\n   ðŸ”¹ Ð¡Ð¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ðµ #{i}:")
                debug_info.append(f"      ÐŸÐ¾Ð·Ð¸Ñ†Ð¸Ñ: {match.start()}-{match.end()}")
                debug_info.append(f"      Ð¡Ð¾Ð²Ð¿Ð°Ð²ÑˆÐ¸Ð¹ Ñ‚ÐµÐºÑÑ‚: '{match.group()}'")
                debug_info.append(f"      ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ (200 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð² Ð¿Ð¾ÑÐ»Ðµ):\n      '{fragment}'")
                
                if fragment:
                    label = {
                        r'Ð£Ð¢Ð’Ð•Ð Ð–Ð”ÐÐ®': 'ðŸ”¹ Ð£Ñ‚Ð²ÐµÑ€Ð¶Ð´Ð°ÑŽÑ‰Ð°Ñ Ð¾Ñ€Ð³Ð°Ð½Ð¸Ð·Ð°Ñ†Ð¸Ñ',
                        r'Ð°Ð´Ñ€ÐµÑ[Ñƒ]?:': 'ðŸ“ ÐÐ´Ñ€ÐµÑ Ð¾Ð±ÑŠÐµÐºÑ‚Ð°', 
                        r'Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð¾Ð¼': 'ðŸ“‹ Ð”ÐµÑ‚Ð°Ð»Ð¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°',
                        r'ÑÐ¾Ð±ÑÑ‚Ð²ÐµÐ½Ð½Ð¸ÐºÐ¾Ð¼': 'ðŸ‘¤ Ð¡Ð¾Ð±ÑÑ‚Ð²ÐµÐ½Ð½Ð¸Ðº',
                        r'ÐšÑ€Ð°Ñ‚ÐºÐ¸Ðµ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ': 'ðŸ“œ Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ‡ÐµÑÐºÐ°Ñ ÑÐ¿Ñ€Ð°Ð²ÐºÐ°'
                    }.get(pattern, f'âš™ï¸ ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ Ð¿Ð¾ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ñƒ "{pattern}"')
                    
                    fragments.append(f"{label}:\n{fragment}\n{'â”'*40}")

        except re.error as e:
            debug_info.append(f"   âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð² Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ðµ: {str(e)}")
            continue

    # Ð’Ñ‹Ð²Ð¾Ð´ Ð¾Ñ‚Ð»Ð°Ð´Ð¾Ñ‡Ð½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð² ÐºÐ¾Ð½ÑÐ¾Ð»ÑŒ
    print("\n".join(debug_info))
    
    return "\n\n".join(fragments) if fragments else "ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð·Ð½Ð°Ñ‡Ð¸Ð¼Ñ‹Ñ… Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ð¾Ð²"
class ProcessingStage(PipelineStage):
    def run(self, data: Dict[str, Any]) -> Dict[str, Any]:
        processing_meta = {
            "timestamp": datetime.now().isoformat(),
            "processed_files": 0,
            "errors": []
        }

        typer.echo(f"âš™ï¸ ProcessingStage input data: {type(data)}")
        typer.echo(f"ðŸ“ ENV limits: fragment={MAX_FRAGMENT_LENGTH}, gpt_text={TEXT_MAX_LENGTH}, head={CHUNK_HEAD}, tail={CHUNK_TAIL}")

        if not isinstance(data, dict):
            typer.echo("â„¹ï¸ Input data is not a dictionary, skipping processing")
            return data

        for block_name, items in data.items():
            if not isinstance(items, list):
                typer.echo(f"ðŸ”¸ Skipping block '{block_name}' (not a list)")
                continue

            typer.echo(f"ðŸ”§ Processing block '{block_name}' with {len(items)} items")
            data[block_name] = [r for r in items if self._process_record(r, processing_meta)]

        data["__processing__"] = processing_meta
        typer.echo(f"âœ… Processed {processing_meta['processed_files']} PDF files")

        if "events" in data:
            for i, event in enumerate(data["events"]):
                typer.echo(f"ðŸ“„ Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚ #{i+1}: {event.get('title', 'Ð‘ÐµÐ· Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ')}")
                
        else:
            typer.echo("âŒ 'events' Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚")

        return data

    def _process_record(self, record: Dict[str, Any], meta: Dict[str, Any]) -> bool:
        if not record.get("file_content") or ".pdf" not in record.get("url", "").lower():
            typer.echo("âŒ Ð¤Ð°Ð¹Ð» Ð½Ðµ PDF, Ð¿Ñ€Ð¾Ð¿ÑƒÑÐº")
            return False

        try:
            text = self._extract_pdf_text(record["file_content"])
            record["text"] = text
            record["event_id"] = get_event_hash(record)

            if is_known_by_hash(record):
                typer.echo(f"â­ï¸ ÐŸÑ€Ð¾Ð¿ÑƒÑÐº: ÑƒÐ¶Ðµ Ð±Ñ‹Ð»Ð¾ â†’ {record['url']}")
                return False

            del record["file_content"]
            meta["processed_files"] += 1
            typer.echo(f"ðŸ“ Extracted text from PDF ({len(text)} chars)")
        except Exception as e:
            error_msg = f"Failed to process PDF: {str(e)}"
            record["text"] = f"[ERROR: {error_msg}]"
            record["error"] = error_msg
            meta["errors"].append({
                "url": record.get("url", "unknown"),
                "error": error_msg
            })
            typer.echo(f"âŒ {error_msg}")
            return False

        regex_patterns = getattr(self.config.processing, "extract_regex", [])
        print ('ÐŸÐÐ¢Ð¢Ð•Ð ÐÐ«', len(regex_patterns), regex_patterns)
        if regex_patterns:
            excerpt = extract_text_fragments(text, regex_patterns)
            print(f"âš™ï¸ Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼Ñ‹Ðµ regex-Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹: {regex_patterns}")
            record["excerpt"] = excerpt
            if not excerpt.strip():
                typer.echo(f"âš ï¸ ÐšÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð° Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹ Ð² Ñ‚ÐµÐºÑÑ‚Ðµ â†’ {record.get('url')}")
            record["gpt_text"] = excerpt
            typer.echo(f"ðŸ” excerpt by regex_patterns â†’ {len(excerpt)} chars")
            typer.echo(f"âœ‚ï¸ gpt_text set to excerpt ({len(excerpt)} chars)")
        else:
            if len(text) > TEXT_MAX_LENGTH:
                record["excerpt"] = f"{text[:CHUNK_HEAD]} ... {text[-CHUNK_TAIL:]}"
                typer.echo(f"âœ‚ï¸ gpt_text trimmed from full text to {len(record['gpt_text'])} chars")
            else:
                record["excerpt"] = text

        return True

    def _extract_pdf_text(self, pdf_content: bytes, max_pages: int = 10) -> str:
        text_parts = []
        doc = fitz.open(stream=BytesIO(pdf_content), filetype="pdf")
        for page_num in range(min(len(doc), max_pages)):
            page = doc.load_page(page_num)
            text = self._extract_page_text(page)
            if text:
                text_parts.append(text)
        return "\n".join(text_parts).strip()

    def _extract_page_text(self, page) -> str:
        text = page.get_text().strip()
        if text:
            return text
        try:
            pix = page.get_pixmap(dpi=300)
            img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
            return pytesseract.image_to_string(img, lang="rus+eng").strip()
        except Exception as e:
            return f"[OCR failed: {str(e)}]"
